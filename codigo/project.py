# -*- coding: utf-8 -*-
"""TFM_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1P7uNop4faXvoCVDXnKLTKHB1tEXGFFe9

**Trabajo Fin de M√°ster: Identificaci√≥n y priorizaci√≥n inteligente de hogares para energ√≠a solar**

Leticia C√≥logan Valero
"""

# Librer√≠as est√°ndar
import os
import shutil
import time
import glob
import cv2

# Manejo de datos
import numpy as np
import pandas as pd

# Visualizaci√≥n
import matplotlib.pyplot as plt

# Im√°genes
from PIL import Image

# Progreso
from tqdm import tqdm

# PyTorch
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split

# Visi√≥n por computador
from torchvision import models, transforms

# Clustering
from sklearn.cluster import KMeans

from google.colab import drive

# Montar Google Drive
drive.mount('/content/drive')

root_path = '/content/drive/MyDrive/bdappv/google/google'

# Rutas a carpetas
images_folder = "/content/drive/MyDrive/bdappv/google/google/imagenes_casas"
masks_folder = "/content/drive/MyDrive/bdappv/google/google/imagenes_casas_mask"

# Creamos las m√°scaras negras para im√°genes sin m√°scara
for img_file in images_folder:
    # Asumimos que las m√°scaras tienen el mismo nombre que las im√°genes
    mask_name = img_file.replace(".jpg", ".png")

    if mask_name not in masks_folder:
        # Cargar la imagen para saber su tama√±o
        img_path = os.path.join(images_folder, img_file)
        img = Image.open(img_path)
        width, height = img.size

        # Crear una m√°scara negra
        empty_mask = np.zeros((height, width), dtype=np.uint8)
        empty_mask_img = Image.fromarray(empty_mask)

        # Guardar la m√°scara negra
        mask_path = os.path.join(masks_folder, mask_name)
        empty_mask_img.save(mask_path)

print("‚úÖ M√°scaras negras creadas para todas las im√°genes sin m√°scara.")

# Listar algunos archivos para revisar (puedes elegir cu√°ntos)
image_files = os.listdir(images_folder)
image_files = image_files[:50]  # Solo 10 para ver r√°pido (cambia el n√∫mero si quieres m√°s)

# Visualizar
for img_file in image_files:
    # Rutas
    img_path = os.path.join(images_folder, img_file)
    mask_name = img_file.replace(".jpg", ".png")  # Ajusta si tu extensi√≥n es diferente
    mask_path = os.path.join(masks_folder, mask_name)

    # Cargar imagen y m√°scara
    img = np.array(Image.open(img_path).convert('RGB'))
    mask = np.array(Image.open(mask_path).convert('L'))  # Convertir la m√°scara a escala de grises

    # Opcional: hacer la m√°scara binaria (0 o 1)
    mask = (mask > 0).astype(np.uint8)

    # Mostrar
    plt.figure(figsize=(10,5))

    plt.subplot(1,2,1)
    plt.imshow(img)
    plt.title("Imagen Original")
    plt.axis('off')

    plt.subplot(1,2,2)
    plt.imshow(img)
    plt.imshow(mask, cmap='Reds', alpha=0.5)  # Superponemos la m√°scara en rojo
    plt.title("Imagen + M√°scara")
    plt.axis('off')

    plt.show()

"""**Primero detectamos si nuestra imagen contiene una casa o no**

En primer lugar se llevar√° a cabo un agrupamiento (clustering) de las im√°genes en funci√≥n de sus caracter√≠sticas visuales, usando ResNet50 como extractor de caracter√≠sticas y K-Means como m√©todo de agrupamiento
"""

#numero de imagenes
count = 0
#extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tif', '.tiff', '.gif')
for root, dirs, files in os.walk(images_folder):
    for fname in files:
        if fname.lower().endswith('.png'):
            count += 1

print(f"Total de im√°genes encontradas: {count}")

# N√∫mero de cl√∫steres y muestras a revisar por cl√∫ster
n_clusters = 30
samples_per_cluster = 10

# Salidas en Drive
cluster_csv = "/content/drive/MyDrive/bdappv/google/google/cluster_labels.csv"
final_csv   = "/content/drive/MyDrive/bdappv/google/google/imagen_labeling.csv"

"""

*   **Extracci√≥n de features**

Se carga una ResNet50 preentrenada en ImageNet.

Se elimina la capa final de clasificaci√≥n, qued√°ndose solo con el tronco de la red para usarla como extractor de caracter√≠sticas visuales.

El extractor devuelve un vector de 2048 dimensiones por imagen."""

#Prepara el extractor de features (ResNet50 sin la cabeza final)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
resnet = models.resnet50(pretrained=True).to(device).eval()
feat_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])

#Transformaciones para extraer embeddings
tf = transforms.Compose([
    transforms.Resize(256),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225]),
])

# Extracci√≥n de features
paths, feats = [], []
for fn in tqdm(os.listdir(images_folder), desc="Extrayendo features"):
    if not fn.lower().endswith(('.jpg', 'jpeg', 'png', 'bmp', 'tif', 'tiff')):
        continue
    fp = os.path.join(images_folder, fn)
    img = Image.open(fp).convert('RGB')
    x = tf(img).unsqueeze(0).to(device)
    with torch.no_grad():
        v = feat_extractor(x).squeeze().cpu().numpy()
    feats.append(v.reshape(-1))
    paths.append(fn)

feats = np.vstack(feats)

# Guardar features y rutas
np.savez("/content/drive/MyDrive/bdappv/google/google/features_resnet50.npz", feats=feats, paths=np.array(paths))
print("‚úÖ Features guardados como .npz")

"""

*   **Clustering**


Se aplica K-Means a los vectores extra√≠dos.

Se crea un DataFrame donde cada imagen tiene asignado su n√∫mero de cl√∫ster."""

# Aplica K-Means y crea un DataFrame con la asignaci√≥n de cl√∫ster
km = KMeans(n_clusters=n_clusters, random_state=0).fit(feats)
df = pd.DataFrame({
    'image': paths,
    'cluster': km.labels_
})

# Muestra por consola ejemplos de cada cl√∫ster
for c in range(n_clusters):
    sample = df[df.cluster==c].sample(samples_per_cluster, random_state=0)['image'].tolist()
    print(f"\nCluster {c}  (total={len(df[df.cluster==c])} im√°genes):")
    for img in sample:
        print("   ", img)

def display_cluster(cluster_id):
    """
    Muestra SAMPLE_PER_CLUSTER im√°genes de un cl√∫ster espec√≠fico.
    Usa matplotlib para desplegar las im√°genes en una fila.
    """
    sample = df[df.cluster == cluster_id].sample(samples_per_cluster, random_state=0)['image'].tolist()
    fig, axes = plt.subplots(1, len(sample), figsize=(15, 5))
    for ax, img_name in zip(axes, sample):
        img_path = os.path.join(images_folder, img_name)
        img = Image.open(img_path).convert('RGB')
        ax.imshow(img)
        ax.set_title(img_name, fontsize=8)
        ax.axis('off')
    plt.suptitle(f"Cluster {cluster_id} - Ejemplos", fontsize=12)
    plt.show()


for c in range(30):
    display_cluster(c)

"""**Etiquetas**
Se etiquetan las im√°genes seg√∫n sean o no clasificadas como casas:

*   0 -> No casa
*   1-> Casa
"""

# Genera CSV para que rellenes manualmente los r√≥tulos de cada cl√∫ster
cluster_df = pd.DataFrame({
    'cluster': list(range(n_clusters)),
    'label':  ['']*n_clusters
})
cluster_df.to_csv(cluster_csv, index=False)
print(f"\nüëâ Revisa {cluster_csv}, escribe en 'label' 'casa' o 'no_casa', y guarda.")

cluster_labels = pd.read_csv(cluster_csv, sep = ';')

# 9) Fusiona la etiqueta de cl√∫ster con cada imagen
cluster_labels['label'] = cluster_labels['label'].map({0:'no_casa', 1:'casa'})
labeled = df.merge(cluster_labels, on='cluster')[['image','label']]
labeled.to_csv(final_csv, index=False)

print("Etiquetas finales:\n", labeled['label'].value_counts())

"""Ahora utilizaremos las im√°genes y sus m√°scaras correspondiente almacenadas en los siguientes directorios:



*   images_folder = "/content/drive/MyDrive/bdappv/google/imagenes_casas"
*   mask_folder = "/content/drive/MyDrive/bdappv/google/imagenes_casas_mask"

"""

csv_path = "/content/drive/MyDrive/bdappv/imagen_labeling.csv"
df = pd.read_csv(csv_path)

images_folder = "/content/drive/MyDrive/bdappv/google/img"
output_folder = "/content/drive/MyDrive/bdappv/google/imagenes_casas"
os.makedirs(output_folder, exist_ok=True)

df_casas = df[df['label'] == 'casa']


print("Columnas del CSV:", df.columns)


for img_name in df_casas['image']:
    src = os.path.join(images_folder, img_name)
    dst = os.path.join(output_folder, img_name)
    if os.path.exists(src):
        shutil.copy2(src, dst)
    else:
        print(f"Imagen no encontrada: {src}")

output_folder = "/content/drive/MyDrive/bdappv/google/google/imagenes_casas"

num_imagenes = len([f for f in os.listdir(output_folder) if os.path.isfile(os.path.join(output_folder, f))])
print(f"N√∫mero de im√°genes clasificadas como 'casa': {num_imagenes}")

output_folder = "/content/drive/MyDrive/bdappv/google/google/imagenes_casas_mask"

# Mismo procedimiento para las m√°scaras

csv_path = "/content/drive/MyDrive/bdappv/imagen_labeling.csv"
df = pd.read_csv(csv_path)

images_folder = "/content/drive/MyDrive/bdappv/google/mask"
output_folder = "/content/drive/MyDrive/bdappv/google/imagenes_casas_mask"
os.makedirs(output_folder, exist_ok=True)

df_casas = df[df['label'] == 'casa']

print("Columnas del CSV:", df.columns)

for img_name in df_casas['image']:
    src = os.path.join(images_folder, img_name)
    dst = os.path.join(output_folder, img_name)
    if os.path.exists(src):
        shutil.copy2(src, dst)
    else:
        print(f"Imagen no encontrada: {src}")

num_imagenes = len([f for f in os.listdir(output_folder) if os.path.isfile(os.path.join(output_folder, f))])
print(f"N√∫mero de im√°genes clasificadas como 'casa': {num_imagenes}")

"""Visualizamos las im√°genes nuevamente clasificadas con sus m√°scaras correspondientes, observando que ya solo se trata de casas."""

image_files = os.listdir(images_folder)
image_files = image_files[:50]


for img_file in image_files:

    img_path = os.path.join(images_folder, img_file)
    mask_name = img_file.replace(".jpg", ".png")
    mask_path = os.path.join(masks_folder, mask_name)


    img = np.array(Image.open(img_path).convert('RGB'))
    mask = np.array(Image.open(mask_path).convert('L'))


    mask = (mask > 0).astype(np.uint8)


    plt.figure(figsize=(10,5))

    plt.subplot(1,2,1)
    plt.imshow(img)
    plt.title("Imagen Original")
    plt.axis('off')

    plt.subplot(1,2,2)
    plt.imshow(img)
    plt.imshow(mask, cmap='Reds', alpha=0.5)
    plt.title("Imagen + M√°scara")
    plt.axis('off')

    plt.show()

"""**Entrenamiento U-Net**

A continuaci√≥n se entranar√°n la red Unet y Mini-Unet para la segmentaci√≥n de paneles solares.
"""

torch.cuda.empty_cache()  # Libera memoria GPU antes de cada epoch

"""**Proceso entrenamiento de la red**

| Fase              | Qu√© se hace                                                    |
|:------------------|:----------------------------------------------------------------|
| Dataset           | Cargar im√°genes + m√°scaras y aplicar transformaciones.          |
| DataLoader        | Gestionar batches, shuffling y cargas paralelas.                 |
| Modelo (U-Net)    | Definir la red para segmentaci√≥n de paneles solares.             |
| Entrenamiento     | Ajustar el modelo con los datos de entrenamiento.                |
| Validaci√≥n        | Evaluar el modelo en datos nunca vistos (validaci√≥n).            |
| Inferencia        | Usar el modelo para detectar paneles en im√°genes nuevas.         |
"""

#Asigna imagen con su m√°scara correspondiente y las transforma para ajustar el tama√±o y que sea compatible
class SolarPanelDataset(Dataset):
    def __init__(self, images_folder, masks_folder, transform=None):
        self.images_folder = images_folder
        self.masks_folder = masks_folder
        self.image_files = os.listdir(images_folder)
        self.transform = transform

    def __len__(self):
        return len(self.image_files)

    def __getitem__(self, idx):
        img_name = self.image_files[idx]
        img_path = os.path.join(self.images_folder, img_name)
        mask_name = img_name.replace(".jpg", ".png")
        mask_path = os.path.join(self.masks_folder, mask_name)

        image = Image.open(img_path).convert('RGB')
        mask = Image.open(mask_path).convert('L')

        if self.transform:
            image = self.transform(image)
            mask = self.transform(mask)

        mask = (mask > 0).float()

        return image, mask

# Transformaciones
transform = transforms.Compose([
    transforms.Resize((128, 128)),
    transforms.ToTensor(),
])

# Creaci√≥n del dataset
images_folder = "/content/drive/MyDrive/bdappv/google/google/imagenes_casas"
masks_folder = "/content/drive/MyDrive/bdappv/google/google/imagenes_casas_mask"
dataset = SolarPanelDataset(images_folder, masks_folder, transform=transform)

def calculate_class_balance(dataset):
    has_panel = 0
    no_panel = 0

    for i in tqdm(range(len(dataset))):
        _, mask = dataset[i]
        if mask.sum() > 0:
            has_panel += 1
        else:
            no_panel += 1

    total = has_panel + no_panel
    print(f"Total im√°genes: {total}")
    print(f"Con paneles solares: {has_panel} ({(has_panel/total)*100:.2f}%)")
    print(f"Sin paneles solares: {no_panel} ({(no_panel/total)*100:.2f}%)")

# ‚úÖ USO:

calculate_class_balance(dataset)

"""Los resultados muestran que el dataset est√° balanceado"""

train_size = int(0.8 * len(dataset))
val_size = len(dataset) - train_size
train_dataset, val_dataset = random_split(dataset, [train_size, val_size])

num_workers = min(8, os.cpu_count())
train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, pin_memory=True, num_workers=num_workers,prefetch_factor=2,persistent_workers=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=num_workers,prefetch_factor=2,persistent_workers=True)

#UNet
class UNet(nn.Module):
    def __init__(self):
        super(UNet, self).__init__()

        def CBR(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            )

        self.enc1 = nn.Sequential(CBR(3, 64), CBR(64, 64))
        self.enc2 = nn.Sequential(CBR(64, 128), CBR(128, 128))
        self.enc3 = nn.Sequential(CBR(128, 256), CBR(256, 256))
        self.enc4 = nn.Sequential(CBR(256, 512), CBR(512, 512))

        self.pool = nn.MaxPool2d(2)

        self.middle = nn.Sequential(CBR(512, 1024), CBR(1024, 1024))

        self.up4 = nn.ConvTranspose2d(1024, 512, 2, stride=2)
        self.dec4 = nn.Sequential(CBR(1024, 512), CBR(512, 512))

        self.up3 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.dec3 = nn.Sequential(CBR(512, 256), CBR(256, 256))

        self.up2 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec2 = nn.Sequential(CBR(256, 128), CBR(128, 128))

        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec1 = nn.Sequential(CBR(128, 64), CBR(64, 64))

        self.final = nn.Conv2d(64, 1, 1)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))

        m = self.middle(self.pool(e4))

        d4 = self.up4(m)
        d4 = torch.cat([d4, e4], dim=1)
        d4 = self.dec4(d4)

        d3 = self.up3(d4)
        d3 = torch.cat([d3, e3], dim=1)
        d3 = self.dec3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)

        out = torch.sigmoid(self.final(d1))
        return out

#Mini UNet
class UNetMini(nn.Module):
    def __init__(self):
        super(UNetMini, self).__init__()

        def CBR(in_channels, out_channels):
            return nn.Sequential(
                nn.Conv2d(in_channels, out_channels, 3, padding=1),
                nn.BatchNorm2d(out_channels),
                nn.ReLU(inplace=True)
            )

        self.enc1 = nn.Sequential(CBR(3, 32), CBR(32, 32))
        self.enc2 = nn.Sequential(CBR(32, 64), CBR(64, 64))
        self.enc3 = nn.Sequential(CBR(64, 128), CBR(128, 128))
        self.enc4 = nn.Sequential(CBR(128, 256), CBR(256, 256))

        self.pool = nn.MaxPool2d(2)

        self.middle = nn.Sequential(CBR(256, 512), CBR(512, 512))

        self.up4 = nn.ConvTranspose2d(512, 256, 2, stride=2)
        self.dec4 = nn.Sequential(CBR(512, 256), CBR(256, 256))

        self.up3 = nn.ConvTranspose2d(256, 128, 2, stride=2)
        self.dec3 = nn.Sequential(CBR(256, 128), CBR(128, 128))

        self.up2 = nn.ConvTranspose2d(128, 64, 2, stride=2)
        self.dec2 = nn.Sequential(CBR(128, 64), CBR(64, 64))

        self.up1 = nn.ConvTranspose2d(64, 32, 2, stride=2)
        self.dec1 = nn.Sequential(CBR(64, 32), CBR(32, 32))

        self.final = nn.Conv2d(32, 1, 1)

    def forward(self, x):
        e1 = self.enc1(x)
        e2 = self.enc2(self.pool(e1))
        e3 = self.enc3(self.pool(e2))
        e4 = self.enc4(self.pool(e3))

        m = self.middle(self.pool(e4))

        d4 = self.up4(m)
        d4 = torch.cat([d4, e4], dim=1)
        d4 = self.dec4(d4)

        d3 = self.up3(d4)
        d3 = torch.cat([d3, e3], dim=1)
        d3 = self.dec3(d3)

        d2 = self.up2(d3)
        d2 = torch.cat([d2, e2], dim=1)
        d2 = self.dec2(d2)

        d1 = self.up1(d2)
        d1 = torch.cat([d1, e1], dim=1)
        d1 = self.dec1(d1)

        out = torch.sigmoid(self.final(d1))
        return out

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNet().to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.BCELoss()

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

model_unet = UNet().to(device)
model_unet_mini = UNetMini().to(device)

print("üìå Resumen de U-Net:")
summary(model_unet, input_size=(3, 128, 128))

print("\nüìå Resumen de U-Net Mini:")
summary(model_unet_mini, input_size=(3, 128, 128))

"""**Entrenamiento de la red Unet**"""

# Definici√≥n de m√©tricas
def dice_coefficient(preds, targets, threshold=0.5):
    preds = (preds > threshold).float()
    smooth = 1e-6
    intersection = (preds * targets).sum()
    return (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)

def iou_score(preds, targets, threshold=0.5):
    preds = (preds > threshold).float()
    smooth = 1e-6
    intersection = (preds * targets).sum()
    union = preds.sum() + targets.sum() - intersection
    return (intersection + smooth) / (union + smooth)

train_losses = []
val_losses = []
val_dice_scores = []
val_iou_scores = []


num_epochs = 50
patience = 8
best_val_loss = float('inf')
epochs_no_improve = 0
best_model_path = "/content/drive/MyDrive/bdappv/google/google/best_model.pth"

# Entrenamiento + validaci√≥n
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    torch.cuda.empty_cache()

    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    train_loss = running_loss / len(train_loader)
    train_losses.append(train_loss)


    model.eval()
    val_running_loss = 0.0
    dice_running = 0.0
    iou_running = 0.0

    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            val_loss = criterion(outputs, masks)
            val_running_loss += val_loss.item()

            dice = dice_coefficient(outputs, masks)
            iou = iou_score(outputs, masks)

            dice_running += dice.item()
            iou_running += iou.item()

    val_loss = val_running_loss / len(val_loader)
    dice_score = dice_running / len(val_loader)
    iou_score_epoch = iou_running / len(val_loader)

    val_losses.append(val_loss)
    val_dice_scores.append(dice_score)
    val_iou_scores.append(iou_score_epoch)

    print(f"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Val Dice: {dice_score:.4f} - Val IoU: {iou_score_epoch:.4f}")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), best_model_path)
        print("‚úÖ Mejor modelo guardado.")
    else:
        epochs_no_improve += 1
        print(f"üî∏ Sin mejora. Paciencia: {epochs_no_improve}/{patience}")

    if epochs_no_improve >= patience:
        print("üõë Early stopping activado.")
        break

model.load_state_dict(torch.load(best_model_path))
model.eval()

plt.figure(figsize=(18,5))

plt.subplot(1,3,1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Evoluci√≥n de la P√©rdida')

plt.subplot(1,3,2)
plt.plot(val_dice_scores, label='Validation Dice', color='green')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.legend()
plt.title('Evoluci√≥n del Dice Coefficient')

plt.subplot(1,3,3)
plt.plot(val_iou_scores, label='Validation IoU', color='purple')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.legend()
plt.title('Evoluci√≥n del IoU')

plt.tight_layout()
plt.show()

def visualize_prediction(model, dataset, idx):
    model.eval()

    image, true_mask = dataset[idx]
    image = image.unsqueeze(0).to(device)

    with torch.no_grad():
        pred_mask = model(image)

    pred_mask = pred_mask.squeeze().cpu().numpy()
    pred_mask = (pred_mask > 0.3).astype(np.uint8)

    image = image.squeeze().cpu().permute(1, 2, 0).numpy()
    true_mask = true_mask.squeeze().cpu().numpy()


    plt.figure(figsize=(15,5))

    plt.subplot(1,3,1)
    plt.imshow(image)
    plt.title('Imagen Real')
    plt.axis('off')

    plt.subplot(1,3,2)
    plt.imshow(true_mask, cmap='gray')
    plt.title('M√°scara Real (Ground Truth)')
    plt.axis('off')

    plt.subplot(1,3,3)
    plt.imshow(pred_mask, cmap='gray')
    plt.title('M√°scara Predicha')
    plt.axis('off')

    plt.show()

visualize_prediction(model, val_dataset, idx=3)

def visualize_gradcam_batch_unet(model, image_batch, layer='enc4', device='cuda'):
    """
    Muestra Grad-CAM, predicci√≥n y original para 4 im√°genes de un batch.

    Args:
        model: modelo U-Net personalizado.
        image_batch: tensor (B, 3, H, W), con al menos 4 im√°genes.
        layer: capa del encoder a usar (ej. 'enc4').
        device: 'cuda' o 'cpu'.
    """
    model.eval()
    image_batch = image_batch.to(device)[:4]  # Tomar las primeras 4 im√°genes

    # Hooks
    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output.detach()

    def backward_hook(module, grad_input, grad_output):
        gradients['value'] = grad_output[0].detach()

    target_layer = getattr(model, layer)
    h1 = target_layer.register_forward_hook(forward_hook)
    h2 = target_layer.register_full_backward_hook(backward_hook)

    # Forward + backward
    outputs = model(image_batch)  # (B, 1, H, W)
    preds = torch.sigmoid(outputs).detach().cpu().squeeze(1).numpy()  # (B, H, W)

    for i in range(4):
        model.zero_grad()
        output = outputs[i:i+1]
        target = output.mean()
        target.backward(retain_graph=True)

        grads = gradients['value'][i]  # (C, H, W)
        acts = activations['value'][i]  # (C, H, W)
        weights = grads.mean(dim=(1, 2), keepdim=True)
        cam = torch.sum(weights * acts, dim=0)
        cam = torch.relu(cam)
        cam = cam / (cam.max() + 1e-8)
        cam_np = cam.cpu().numpy()

        img = image_batch[i].cpu().permute(1, 2, 0).numpy()
        cam_resized = cv2.resize(cam_np, (img.shape[1], img.shape[0]))
        pred_mask = preds[i]

        fig, axs = plt.subplots(1, 3, figsize=(15, 4))
        axs[0].imshow(img)
        axs[0].set_title(f"Imagen {i+1}")
        axs[0].axis('off')

        axs[1].imshow(pred_mask, cmap='gray')
        axs[1].set_title("M√°scara predicha")
        axs[1].axis('off')

        axs[2].imshow(img)
        axs[2].imshow(cam_resized, cmap='jet', alpha=0.5)
        axs[2].set_title(f"Grad-CAM ({layer})")
        axs[2].axis('off')

        plt.tight_layout()
        plt.show()

    h1.remove()
    h2.remove()

val_iter = iter(val_loader)
images, _ = next(val_iter)

visualize_gradcam_batch_unet(model, images, layer='enc4', device=device)

"""**Entrenamiento de la red Mini Unet**"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
model = UNetMini().to(device)

optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.BCELoss()

train_losses, val_losses = [], []
val_dice_scores, val_iou_scores = [], []

num_epochs = 50
patience = 8
best_val_loss = float('inf')
epochs_no_improve = 0
best_model_path = "/content/drive/MyDrive/bdappv/google/google/best_model_miniunet.pth"

# Entrenamiento + validaci√≥n
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    torch.cuda.empty_cache()

    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    train_loss = running_loss / len(train_loader)
    train_losses.append(train_loss)

    model.eval()
    val_running_loss = 0.0
    dice_running = 0.0
    iou_running = 0.0

    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            val_loss = criterion(outputs, masks)
            val_running_loss += val_loss.item()

            dice = dice_coefficient(outputs, masks)
            iou = iou_score(outputs, masks)

            dice_running += dice.item()
            iou_running += iou.item()

    val_loss = val_running_loss / len(val_loader)
    dice_score = dice_running / len(val_loader)
    iou_score_epoch = iou_running / len(val_loader)

    val_losses.append(val_loss)
    val_dice_scores.append(dice_score)
    val_iou_scores.append(iou_score_epoch)

    print(f"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - "
          f"Val Dice: {dice_score:.4f} - Val IoU: {iou_score_epoch:.4f}")

    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), best_model_path)
        print("‚úÖ Mejor modelo guardado.")
    else:
        epochs_no_improve += 1
        print(f"üî∏ Sin mejora. Paciencia: {epochs_no_improve}/{patience}")

    if epochs_no_improve >= patience:
        print("üõë Early stopping activado.")
        break

model.load_state_dict(torch.load(best_model_path))
model.eval()

plt.figure(figsize=(18,5))

plt.subplot(1,3,1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Evoluci√≥n de la P√©rdida')

plt.subplot(1,3,2)
plt.plot(val_dice_scores, label='Validation Dice', color='green')
plt.xlabel('Epochs')
plt.ylabel('Dice Coefficient')
plt.legend()
plt.title('Evoluci√≥n del Dice Coefficient')

plt.subplot(1,3,3)
plt.plot(val_iou_scores, label='Validation IoU', color='purple')
plt.xlabel('Epochs')
plt.ylabel('IoU Score')
plt.legend()
plt.title('Evoluci√≥n del IoU')

plt.tight_layout()
plt.show()

visualize_prediction(model, val_dataset, idx=3)
visualize_prediction(model, val_dataset, idx=56)
visualize_prediction(model, val_dataset, idx=90)
visualize_prediction(model, val_dataset, idx=87)

val_iter = iter(val_loader)
images, _ = next(val_iter)

visualize_gradcam_batch_unet(model, images, layer='enc4', device=device)

def show_feature_maps(model, image_tensor, layer_name='enc3', num_maps=8, device='cuda'):
    """
    Visualiza los primeros feature maps de una capa del modelo U-Net.

    Args:
        model: tu modelo U-Net
        image_tensor: tensor con shape (1, 3, H, W)
        layer_name: nombre de la capa (ej. 'enc1', 'enc2', etc.)
        num_maps: cu√°ntos mapas mostrar
        device: cuda o cpu
    """
    model.eval()
    image_tensor = image_tensor.to(device)

    fmap = {}

    def hook_fn(module, input, output):
        fmap['value'] = output.detach().cpu()

    # Registrar hook
    layer = getattr(model, layer_name)
    hook = layer.register_forward_hook(hook_fn)

    # Forward
    with torch.no_grad():
        _ = model(image_tensor)

    hook.remove()

    activations = fmap['value'][0]  # shape: (C, H, W)
    num_maps = min(num_maps, activations.shape[0])

    # Mostrar mapas
    plt.figure(figsize=(15, 5))
    for i in range(num_maps):
        plt.subplot(1, num_maps, i+1)
        plt.imshow(activations[i], cmap='viridis')
        plt.axis('off')
        plt.title(f'FM {i+1}')
    plt.suptitle(f"Feature maps - capa {layer_name}", fontsize=14)
    plt.tight_layout()
    plt.show()

# Tomar una imagen del val_loader
images, _ = next(iter(val_loader))
image_tensor = images[0].unsqueeze(0)  # (1, 3, H, W)

# Mostrar feature maps de enc3
show_feature_maps(model, image_tensor, layer_name='enc1', num_maps=8, device=device)

images, _ = next(iter(val_loader))
image_tensor = images[0].unsqueeze(0)

show_feature_maps(model, image_tensor, layer_name='enc2', num_maps=8, device=device)

images, _ = next(iter(val_loader))
image_tensor = images[0].unsqueeze(0)  # (1, 3, H, W)

show_feature_maps(model, image_tensor, layer_name='enc3', num_maps=8, device=device)

images, _ = next(iter(val_loader))
image_tensor = images[0].unsqueeze(0)

show_feature_maps(model, image_tensor, layer_name='enc4', num_maps=8, device=device)

"""**Fine tuning**

A continuaci√≥n utilizaremos como encoder ResNet34 solo para la capa de clasificaci√≥n
"""

!pip install segmentation-models-pytorch

import segmentation_models_pytorch as smp

# Modelo U-Net con ResNet34 preentrenado
model = smp.Unet(
    encoder_name="resnet34",        # Encoder preentrenado en ImageNet
    encoder_weights="imagenet",
    in_channels=3,                  # 3 canales RGB
    classes=1,                      # Salida binaria
).to('cuda' if torch.cuda.is_available() else 'cpu')

optimizer = optim.Adam(model.parameters(), lr=1e-4)
criterion = nn.BCEWithLogitsLoss()

def dice_coefficient(preds, targets, threshold=0.5):
    preds = torch.sigmoid(preds)
    preds = (preds > threshold).float()
    smooth = 1e-6
    intersection = (preds * targets).sum()
    return (2. * intersection + smooth) / (preds.sum() + targets.sum() + smooth)

def iou_score(preds, targets, threshold=0.5):
    preds = torch.sigmoid(preds)
    preds = (preds > threshold).float()
    smooth = 1e-6
    intersection = (preds * targets).sum()
    union = preds.sum() + targets.sum() - intersection
    return (intersection + smooth) / (union + smooth)

train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0)

num_epochs = 50
patience = 5
best_val_loss = float('inf')
epochs_no_improve = 0
model_path = "/content/drive/MyDrive/bdappv/google/google/best_model_resnet.pth"

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
train_losses, val_losses, val_dice_scores, val_iou_scores = [], [], [], []

for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for images, masks in train_loader:
        images = images.to(device)
        masks = masks.to(device)

        optimizer.zero_grad()
        outputs = model(images)
        loss = criterion(outputs, masks)
        loss.backward()
        optimizer.step()

        running_loss += loss.item()

    train_loss = running_loss / len(train_loader)
    train_losses.append(train_loss)

    # Validaci√≥n
    model.eval()
    val_loss = 0.0
    dice = 0.0
    iou = 0.0

    with torch.no_grad():
        for images, masks in val_loader:
            images = images.to(device)
            masks = masks.to(device)

            outputs = model(images)
            val_loss += criterion(outputs, masks).item()

            dice += dice_coefficient(outputs, masks).item()
            iou += iou_score(outputs, masks).item()

    val_loss /= len(val_loader)
    dice /= len(val_loader)
    iou /= len(val_loader)

    val_losses.append(val_loss)
    val_dice_scores.append(dice)
    val_iou_scores.append(iou)

    print(f"Epoch [{epoch+1}/{num_epochs}] - Train Loss: {train_loss:.4f} - Val Loss: {val_loss:.4f} - Val Dice: {dice:.4f} - Val IoU: {iou:.4f}")

    # Early stopping
    if val_loss < best_val_loss:
        best_val_loss = val_loss
        epochs_no_improve = 0
        torch.save(model.state_dict(), model_path)
        print("‚úÖ Modelo mejorado guardado.")
    else:
        epochs_no_improve += 1
        print(f"üî∏ Sin mejora. Paciencia: {epochs_no_improve}/{patience}")

    if epochs_no_improve >= patience:
        print("üõë Early stopping activado.")
        break

model.load_state_dict(torch.load(model_path))
model.eval()

plt.figure(figsize=(18,5))

plt.subplot(1,3,1)
plt.plot(train_losses, label='Train Loss')
plt.plot(val_losses, label='Val Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('P√©rdida')

plt.subplot(1,3,2)
plt.plot(val_dice_scores, label='Val Dice', color='green')
plt.xlabel('Epochs')
plt.ylabel('Dice')
plt.legend()
plt.title('Dice Coefficient')

plt.subplot(1,3,3)
plt.plot(val_iou_scores, label='Val IoU', color='purple')
plt.xlabel('Epochs')
plt.ylabel('IoU')
plt.legend()
plt.title('IoU')

plt.tight_layout()
plt.show()

visualize_prediction(model, val_dataset, idx=3)
visualize_prediction(model, val_dataset, idx=56)
visualize_prediction(model, val_dataset, idx=90)
visualize_prediction(model, val_dataset, idx=87)

def visualize_batch_with_gradcam(model, image_batch, layer='layer4', device='cuda', max_images=4):
    """
    Visualiza varias im√°genes con m√°scara predicha y Grad-CAM para smp.Unet.

    Args:
        model: modelo U-Net (smp) con encoder tipo resnet.
        image_batch: tensor (B, 3, H, W)
        layer: capa del encoder (ej. 'layer4')
        device: 'cuda' o 'cpu'
        max_images: cu√°ntas im√°genes mostrar (m√°x)
    """
    model.eval()
    image_batch = image_batch.to(device)[:max_images]
    image_batch.requires_grad_()

    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output.detach()

    def backward_hook(module, grad_input, grad_output):
        gradients['value'] = grad_output[0].detach()

    hook_layer = getattr(model.encoder, layer)
    h1 = hook_layer.register_forward_hook(forward_hook)
    h2 = hook_layer.register_full_backward_hook(backward_hook)

    output = model(image_batch)
    pred_masks = torch.sigmoid(output).detach().cpu().squeeze(1).numpy()


    target = output.mean()
    model.zero_grad()
    target.backward()

    grads = gradients['value']  # (B, C, H, W)
    acts = activations['value']  # (B, C, H, W)

    fig, axs = plt.subplots(max_images, 3, figsize=(15, 4 * max_images))

    if max_images == 1:
        axs = [axs]

    for i in range(max_images):
        img = denormalize(image_batch[i].cpu(), [0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        img_np = img.permute(1, 2, 0).detach().numpy()
        mask_np = pred_masks[i]

        weights = grads[i].mean(dim=(1, 2), keepdim=True)
        cam = torch.sum(weights * acts[i], dim=0)
        cam = torch.relu(cam)
        cam = cam / (cam.max() + 1e-8)
        cam_np = cam.cpu().numpy()
        cam_resized = cv2.resize(cam_np, (img_np.shape[1], img_np.shape[0]))


        axs[i][0].imshow(img_np)
        axs[i][0].set_title(f"Imagen {i+1}")
        axs[i][0].axis('off')

        axs[i][1].imshow(mask_np, cmap='gray')
        axs[i][1].set_title("M√°scara predicha")
        axs[i][1].axis('off')

        axs[i][2].imshow(img_np)
        axs[i][2].imshow(cam_resized, cmap='jet', alpha=0.5)
        axs[i][2].set_title(f"Grad-CAM ({layer})")
        axs[i][2].axis('off')

    plt.tight_layout()
    plt.show()

    h1.remove()
    h2.remove()

images, _ = next(iter(val_loader))
visualize_batch_with_gradcam(model, images, layer='layer4', device=device, max_images=4)

def visualize_feature_maps(model, image_tensor, layer='layer4', device='cuda', num_maps=8):
    """
    Visualiza feature maps de una capa del encoder (ej. layer4) para modelos como smp.Unet.

    Args:
        model: modelo smp.Unet
        image_tensor: una imagen tensor (1, 3, H, W)
        layer: capa del encoder a inspeccionar ('layer1', 'layer2', etc.)
        device: 'cuda' o 'cpu'
        num_maps: cu√°ntos feature maps mostrar
    """
    model.eval()
    image_tensor = image_tensor.to(device)

    activations = {}

    def forward_hook(module, input, output):
        activations['value'] = output.detach().cpu()

    layer_module = getattr(model.encoder, layer)
    hook = layer_module.register_forward_hook(forward_hook)

    _ = model(image_tensor)


    fmap = activations['value'][0]  # (C, H, W)
    num_maps = min(num_maps, fmap.shape[0])

    plt.figure(figsize=(15, 5))
    for i in range(num_maps):
        plt.subplot(1, num_maps, i + 1)
        plt.imshow(fmap[i], cmap='viridis')
        plt.axis('off')
        plt.title(f'FM {i+1}')
    plt.suptitle(f'Feature Maps - Encoder {layer}', fontsize=14)
    plt.tight_layout()
    plt.show()

    hook.remove()

images, _ = next(iter(val_loader))
img = images[0].unsqueeze(0)  # (1, 3, H, W)

visualize_feature_maps(model, img, layer='layer1', device=device, num_maps=8)

images, _ = next(iter(val_loader))
img = images[0].unsqueeze(0)  # (1, 3, H, W)

visualize_feature_maps(model, img, layer='layer2', device=device, num_maps=8)

images, _ = next(iter(val_loader))
img = images[0].unsqueeze(0)
visualize_feature_maps(model, img, layer='layer3', device=device, num_maps=8)

images, _ = next(iter(val_loader))
img = images[0].unsqueeze(0)
visualize_feature_maps(model, img, layer='layer4', device=device, num_maps=8)

"""**Validaci√≥n:**  Probamos los modelos entrenamos con imagenes satelites del pueblo de Molina de Segura en Murcia"""

root_path = '/content/drive/MyDrive/bdappv/google/google/validation'
# Rutas a carpetas
images_folder = "/content/drive/MyDrive/bdappv/google/google/validation/img"
masks_folder = "/content/drive/MyDrive/bdappv/google/google/validation/mask"

for img_file in os.listdir(images_folder):
    mask_name = img_file
    if mask_name not in os.listdir(masks_folder):
        img_path = os.path.join(images_folder, img_file)
        img = Image.open(img_path)
        width, height = img.size

        empty_mask = np.zeros((height, width), dtype=np.uint8)
        empty_mask_img = Image.fromarray(empty_mask)

        mask_path = os.path.join(masks_folder, mask_name)
        empty_mask_img.save(mask_path)

print("‚úÖ M√°scaras negras creadas para todas las im√°genes sin m√°scara.")

image_files = os.listdir(images_folder)
image_files = image_files[:25]

for img_file in image_files:

    img_path = os.path.join(images_folder, img_file)
    mask_name = img_file.replace(".jpg", ".png")
    mask_path = os.path.join(masks_folder, mask_name)

    img = np.array(Image.open(img_path).convert('RGB'))
    mask = np.array(Image.open(mask_path).convert('L'))

    mask = (mask > 0).astype(np.uint8)

    plt.figure(figsize=(10,5))

    plt.subplot(1,2,1)
    plt.imshow(img)
    plt.title("Imagen Original")
    plt.axis('off')

    plt.subplot(1,2,2)
    plt.imshow(img)
    plt.imshow(mask, cmap='Reds', alpha=0.5)
    plt.title("Imagen + M√°scara")
    plt.axis('off')

    plt.show()

#cargamos los mejores modelos obtenidos en el entrenamiento
unet = "/content/drive/MyDrive/bdappv/google/google/best_model.pth"
mini_unet = "/content/drive/MyDrive/bdappv/google/google/best_model_miniunet.pth"
resnet_unet = "/content/drive/MyDrive/bdappv/google/google/best_model_resnet.pth"

dataset = SolarPanelDataset(images_folder, masks_folder, transform=transform)

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

model = UNet()
model.load_state_dict(torch.load(unet, map_location=torch.device('cpu')))
model.to(device)
model.eval()

val_loader = DataLoader(dataset, batch_size=1, shuffle=False)

val_loader = DataLoader(dataset, batch_size=1, shuffle=False)

model.eval().cuda()


total_dice = 0
total_iou = 0
n = 0

with torch.no_grad():
    for images, masks in val_loader:
        images = images.cuda()
        masks = masks.cuda()

        outputs = model(images)
        outputs = torch.sigmoid(outputs)

        dice = dice_coefficient(outputs, masks)
        iou = iou_score(outputs, masks)

        total_dice += dice.item()
        total_iou += iou.item()
        n += 1

avg_dice = total_dice / n
avg_iou = total_iou / n

print(f"‚úÖ Promedio Dice: {avg_dice:.4f}")
print(f"‚úÖ Promedio IoU : {avg_iou:.4f}")

for i in range(10):
    visualize_prediction(model, dataset, idx=i)

visualize_gradcam_dataset_unet(
    model=model,
    dataset=dataset,
    layer='enc4',
    device=device,
    max_images=10
)

"""**MiniUnet()**"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
print(f"Using device: {device}")

model = UNetMini()
model.load_state_dict(torch.load(mini_unet, map_location=torch.device('cpu')))

model.to(device)
model.eval()

val_loader = DataLoader(dataset, batch_size=1, shuffle=False)

model.eval()

total_dice = 0
total_iou = 0
n = 0

with torch.no_grad():
    for images, masks in val_loader:
        images = images
        masks = masks

        outputs = model(images)
        outputs = torch.sigmoid(outputs)

        dice = dice_coefficient(outputs, masks)
        iou = iou_score(outputs, masks)

        total_dice += dice.item()
        total_iou += iou.item()
        n += 1

avg_dice = total_dice / n
avg_iou = total_iou / n

print(f"‚úÖ Promedio Dice: {avg_dice:.4f}")
print(f"‚úÖ Promedio IoU : {avg_iou:.4f}")

for i in range(10):
    visualize_prediction(model, dataset, idx=i)

visualize_gradcam_dataset_unet(
    model=model,
    dataset=dataset,
    layer='enc4',
    device=device,
    max_images=10
)

"""**Unet + Resnet**"""

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

model = smp.Unet(
    encoder_name="resnet34",
    encoder_weights="imagenet",
    in_channels=3,
    classes=1
).to(device)

model.load_state_dict(torch.load(resnet_unet, map_location=device))
model.eval()

val_loader = DataLoader(dataset, batch_size=1, shuffle=False)

total_dice = 0.0
total_iou = 0.0
n = 0

with torch.no_grad():
    for images, masks in val_loader:
        images = images.to(device)
        masks = masks.to(device)

        outputs = model(images)

        total_dice += dice_coefficient(outputs, masks).item()
        total_iou += iou_score(outputs, masks).item()
        n += 1

print(f"‚úÖ Dice promedio: {total_dice / n:.4f}")
print(f"‚úÖ IoU  promedio: {total_iou / n:.4f}")

def visualize_all_predictions(model, dataset, device='cuda', max_images=None):
    """
    Visualiza todas (o un n√∫mero limitado de) las predicciones del modelo sobre el dataset.

    Args:
        model: Modelo entrenado (U-Net, etc.)
        dataset: Dataset de validaci√≥n
        device: 'cuda' o 'cpu'
        max_images: M√°ximo n√∫mero de im√°genes a mostrar (None para todas)
    """
    model.eval()
    num_images = len(dataset) if max_images is None else min(max_images, len(dataset))

    for idx in tqdm(range(num_images)):
        image, mask = dataset[idx]
        image_tensor = image.unsqueeze(0).to(device)

        with torch.no_grad():
            output = model(image_tensor)
            pred_mask = torch.sigmoid(output).squeeze().cpu().numpy()

        image_np = image.permute(1, 2, 0).cpu().numpy()
        mask_np = mask.squeeze().cpu().numpy()

        plt.figure(figsize=(15, 4))
        plt.subplot(1, 3, 1)
        plt.imshow(image_np)
        plt.title(f"Imagen {idx}")
        plt.axis("off")

        plt.subplot(1, 3, 2)
        plt.imshow(mask_np, cmap='gray')
        plt.title("M√°scara real")
        plt.axis("off")

        plt.subplot(1, 3, 3)
        plt.imshow(pred_mask, cmap='gray')
        plt.title("M√°scara predicha")
        plt.axis("off")

        plt.tight_layout()
        plt.show()

visualize_all_predictions(model, dataset, device=device)

def visualize_gradcam_smp_unet_all(model, dataset, device='cuda', layer_name='encoder.layer4', max_images=None):
    """
    Visualiza Grad-CAM para todas las im√°genes del dataset usando un modelo de smp.Unet con ResNet34.
    """
    model.eval()
    model.to(device)

    activations = {}
    gradients = {}

    def forward_hook(module, input, output):
        activations['value'] = output.detach()

    def backward_hook(module, grad_input, grad_output):
        gradients['value'] = grad_output[0].detach()

    target_layer = dict([*model.named_modules()])[layer_name]
    h1 = target_layer.register_forward_hook(forward_hook)
    h2 = target_layer.register_full_backward_hook(backward_hook)

    num_images = len(dataset) if max_images is None else min(max_images, len(dataset))

    for idx in tqdm(range(num_images)):
        image, _ = dataset[idx]
        image_tensor = image.unsqueeze(0).to(device)

        output = model(image_tensor)
        pred_mask = torch.sigmoid(output).detach().cpu().squeeze().numpy()

        model.zero_grad()
        output.mean().backward()

        grads = gradients['value'].squeeze()
        acts = activations['value'].squeeze()
        weights = grads.mean(dim=(1, 2), keepdim=True)
        cam = torch.sum(weights * acts, dim=0)
        cam = torch.relu(cam)
        cam = cam / (cam.max() + 1e-8)
        cam_np = cam.cpu().numpy()

        img_np = image.permute(1, 2, 0).cpu().numpy()
        cam_resized = cv2.resize(cam_np, (img_np.shape[1], img_np.shape[0]))

        plt.figure(figsize=(15, 4))

        plt.subplot(1, 3, 1)
        plt.imshow(img_np)
        plt.title(f"Imagen {idx}")
        plt.axis("off")

        plt.subplot(1, 3, 2)
        plt.imshow(pred_mask, cmap='gray')
        plt.title("M√°scara predicha")
        plt.axis("off")

        plt.subplot(1, 3, 3)
        plt.imshow(img_np)
        plt.imshow(cam_resized, cmap='jet', alpha=0.5)
        plt.title("Grad-CAM (layer4)")
        plt.axis("off")

        plt.tight_layout()
        plt.show()

    h1.remove()
    h2.remove()

visualize_gradcam_smp_unet_all(
    model=model,
    dataset=dataset,
    device=device,
    layer_name='encoder.layer4',
    max_images=25
)

!pip freeze > requirements.txt